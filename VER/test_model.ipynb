{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2FeatureExtractor, HubertModel\n",
    "import torchaudio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import pickle\n",
    "import requests\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "import threading\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HuBERT 특성 추출기\n",
    "class HuBERTFeatureExtractor:\n",
    "    def __init__(self, model_name=\"facebook/hubert-base-ls960\"):\n",
    "        self.processor = Wav2Vec2FeatureExtractor.from_pretrained(model_name)\n",
    "        self.model = HubertModel.from_pretrained(model_name)\n",
    "        self.model.eval()\n",
    "\n",
    "    def load_audio(self, audio_file):\n",
    "        waveform, sample_rate = torchaudio.load(audio_file)\n",
    "        return waveform, sample_rate\n",
    "\n",
    "    def preprocess_audio(self, waveform, sample_rate, target_sample_rate=16000, max_length=10):\n",
    "        if waveform.size(0) > 1:\n",
    "            waveform = waveform.mean(dim=0, keepdim=True)\n",
    "\n",
    "        if sample_rate != target_sample_rate:\n",
    "            resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=target_sample_rate)\n",
    "            waveform = resampler(waveform)\n",
    "\n",
    "        max_samples = target_sample_rate * max_length\n",
    "        if waveform.size(1) > max_samples:\n",
    "            waveform = waveform[:, :max_samples]\n",
    "\n",
    "        return waveform\n",
    "\n",
    "    def extract_features(self, audio_file):\n",
    "        waveform, sample_rate = self.load_audio(audio_file)\n",
    "        waveform = self.preprocess_audio(waveform, sample_rate)\n",
    "\n",
    "        if waveform.dim() == 1:\n",
    "            waveform = waveform.unsqueeze(0)\n",
    "        elif waveform.dim() == 2:\n",
    "            if waveform.size(0) > 1:\n",
    "                waveform = waveform.mean(dim=0, keepdim=True)\n",
    "        elif waveform.dim() == 3:\n",
    "            waveform = waveform.squeeze(0)\n",
    "            if waveform.size(0) > 1:\n",
    "                waveform = waveform.mean(dim=0, keepdim=True)\n",
    "\n",
    "        inputs = self.processor(waveform, sampling_rate=16000, return_tensors=\"pt\", padding=True)\n",
    "        input_values = inputs.input_values\n",
    "\n",
    "        input_values = input_values.squeeze(1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(input_values)\n",
    "\n",
    "        features = outputs.last_hidden_state\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 감정 데이터셋 클래스\n",
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, audio_files, labels, feature_extractor, label_encoder_path):\n",
    "        self.audio_files = audio_files\n",
    "        self.labels = labels\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.label_encoder = LabelEncoder()\n",
    "\n",
    "        if label_encoder_path and os.path.exists(label_encoder_path):\n",
    "            with open(label_encoder_path, 'rb') as f:\n",
    "                self.label_encoder = pickle.load(f)\n",
    "            print(f\"LabelEncoder loaded from {label_encoder_path}\")\n",
    "        else:\n",
    "            self.label_encoder.fit(labels)\n",
    "            if label_encoder_path:\n",
    "                with open(label_encoder_path, 'wb') as f:\n",
    "                    pickle.dump(self.label_encoder, f)\n",
    "            print(f\"LabelEncoder saved to {label_encoder_path}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        audio_file = self.audio_files[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        features = self.feature_extractor.extract_features(audio_file)\n",
    "        features = features.squeeze(0)\n",
    "\n",
    "        label = self.label_encoder.transform([label])[0]\n",
    "\n",
    "        return features, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer 모델 (감정 인식용)\n",
    "class EmotionTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(EmotionTransformer, self).__init__()\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=input_dim, nhead=16),\n",
    "            num_layers=8\n",
    "        )\n",
    "        self.fc = nn.Linear(input_dim, num_classes)\n",
    "\n",
    "    def forward(self, x, src_key_padding_mask=None):\n",
    "        x = self.transformer(x, src_key_padding_mask=src_key_padding_mask)\n",
    "        x = x.mean(dim=0)  # 평균을 사용\n",
    "        output = self.fc(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 함수 정의\n",
    "def test_model(test_dataloader, model, dataset):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    ground_truth = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for features, labels in test_dataloader:\n",
    "            features = features.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # 모델에 입력\n",
    "            features = features.permute(1, 0, 2)\n",
    "\n",
    "            outputs = model(features)\n",
    "\n",
    "            predicted_labels = torch.argmax(outputs, dim=1)\n",
    "            predictions.extend(predicted_labels.cpu().tolist())\n",
    "            ground_truth.extend(labels.cpu().tolist())\n",
    "\n",
    "    # 예측 결과 반환\n",
    "    return predictions, ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    features = [item[0] for item in batch]  # 각 샘플의 feature 추출\n",
    "    labels = torch.tensor([item[1] for item in batch])  # 각 샘플의 label 추출\n",
    "    \n",
    "    # 각 feature의 크기 확인 후, tensor로 변환\n",
    "    features = [f.squeeze(0) if len(f.shape) == 3 else f for f in features]\n",
    "    \n",
    "    # 시퀀스 패딩 적용 (seq_len을 동일하게 맞춤)\n",
    "    features = pad_sequence(features, batch_first=True, padding_value=0)  # (batch_size, max_seq_len, feature_dim)\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TMDB API 키\n",
    "TMDB_API_KEY = \"df9a0caaf2a07ee6babd7024a6accaf8\"\n",
    "    \n",
    "EMOTION_TO_GENRE = {\n",
    "    '기쁨': 35,  # Comedy\n",
    "    '슬픔': 18,  # Drama\n",
    "    '분노': 53,  # Thriller\n",
    "    '불안': 27,  # Horror\n",
    "    '상처': 80,  # Crime\n",
    "    '당황': 28,  # Action\n",
    "    '중립': 10751,  # Family\n",
    "}\n",
    "\n",
    "def get_recommendations(emotion, result_num=10, api_key=TMDB_API_KEY):\n",
    "    # 감정 매핑 확인\n",
    "    genre_id = EMOTION_TO_GENRE.get(emotion)\n",
    "    if not genre_id:\n",
    "        return f\"'{emotion}'에 해당하는 추천 장르가 없습니다. 감정을 다시 입력해주세요.\"\n",
    "\n",
    "    # TMDB Discover API 호출\n",
    "    url = f\"https://api.themoviedb.org/3/discover/movie\"\n",
    "    params = {\n",
    "        \"api_key\": api_key,\n",
    "        \"include_video\": True,\n",
    "        \"with_genres\": genre_id,\n",
    "        \"sort_by\": \"popularity.desc\",  # 인기 순으로 정렬\n",
    "        \"language\": \"ko-KR\",          # 한국어 결과\n",
    "        \"vote_average.gte\": 7.0,      # 평점 7 이상\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code != 200:\n",
    "        return f\"TMDB API 호출 실패: {response.status_code}\"\n",
    "\n",
    "    data = response.json()\n",
    "    results = data.get(\"results\", [])\n",
    "\n",
    "    if not results:\n",
    "        return f\"'{emotion}'에 맞는 추천 콘텐츠를 찾을 수 없습니다.\"\n",
    "\n",
    "    # 추천 콘텐츠 추출\n",
    "    recommendations = []\n",
    "    for movie in results[:result_num]:  # 상위 N개만 추출\n",
    "        recommendations.append({\n",
    "            \"title\": movie.get(\"title\"),\n",
    "            \"overview\": movie.get(\"overview\"),\n",
    "            \"vote_average\": movie.get(\"vote_average\"),\n",
    "            \"release_date\": movie.get(\"release_date\"),\n",
    "        })\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "녹음 시작. 'Enter' 키를 누르면 녹음을 멈춥니다.\n",
      "녹음 중단 중...\n",
      "'./record files/output.wav' 파일로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 설정\n",
    "fs = 44100  # 샘플링 레이트\n",
    "output_filename = \"./record files/output.wav\"  # 저장할 파일 이름\n",
    "stop_recording = False  # 녹음 중단 플래그\n",
    "seconds = 10 # 녹음 시간(초)\n",
    "\n",
    "\n",
    "def record_audio(): # 마이크로 음성을 녹음하는 함수.\n",
    "    global stop_recording, audio_data\n",
    "    print(\"녹음 시작. 'Enter' 키를 누르면 녹음을 멈춥니다.\")\n",
    "    audio_data = sd.rec(int(60 * fs), samplerate=fs, channels=1, dtype='int16')  # 최대 60초 녹음\n",
    "    while not stop_recording:\n",
    "        sd.sleep(100)  # 짧은 대기(0.1초)\n",
    "    sd.stop()  # 녹음 중단\n",
    "    print(\"녹음 중단 중...\")\n",
    "\n",
    "\n",
    "def wait_for_stop(): # 사용자가 'Enter' 키를 누를 때까지 대기.\n",
    "    global stop_recording\n",
    "    while not stop_recording:\n",
    "        command = input(\"입력: \")\n",
    "        if command.strip().lower() == \"\":\n",
    "            stop_recording = True\n",
    "\n",
    "\n",
    "# 스레드 생성 및 실행\n",
    "recording_thread = threading.Thread(target=record_audio)\n",
    "input_thread = threading.Thread(target=wait_for_stop)\n",
    "\n",
    "recording_thread.start()\n",
    "input_thread.start()\n",
    "\n",
    "recording_thread.join()\n",
    "input_thread.join()\n",
    "\n",
    "# 녹음 데이터를 파일로 저장\n",
    "write(output_filename, fs, audio_data[:fs * seconds])\n",
    "print(f\"'{output_filename}' 파일로 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = \"2025-03-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoder loaded from ./model/label_encoder.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4h/8jkvbs3n7tlcqj21nw5kbbqm0000gn/T/ipykernel_46758/2724577874.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(model_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: ['기쁨' '슬픔' '분노' '당황' '분노' '불안' '중립']\n",
      "Ground Truth: ['기쁨' '슬픔' '분노' '불안' '상처' '당황' '중립']\n",
      "Accuracy: 0.5714\n"
     ]
    }
   ],
   "source": [
    "### 정확도 계산(테스트)\n",
    "\n",
    "# 테스트 데이터 준비\n",
    "test_audio_files = [\"./dataset/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/2.Validation/원천데이터/1.감정/1.기쁨/0029_G2A4E1S0C0_KJE/0029_G2A4E1S0C0_KJE_001970.wav\", \"./dataset/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/2.Validation/원천데이터/1.감정/2.슬픔/0033_G2A3E2S0C0_KMA/0033_G2A3E2S0C0_KMA_000020.wav\", \"./dataset/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/2.Validation/원천데이터/1.감정/3.분노/0018_G2A3E3S0C0_JBR/0018_G2A3E3S0C0_JBR_000019.wav\", \"./dataset/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/2.Validation/원천데이터/1.감정/4.불안/0012_G1A2E4S0C0_CHY/0012_G1A2E4S0C0_CHY_000011.wav\", \"./dataset/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/2.Validation/원천데이터/1.감정/5.상처/0005_G1A3E5S0C0_LJB/0005_G1A3E5S0C0_LJB_000014.wav\", \"./dataset/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/2.Validation/원천데이터/1.감정/6.당황/0020_G2A4E6S0C0_HGW/0020_G2A4E6S0C0_HGW_000009.wav\", \"./dataset/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/2.Validation/원천데이터/1.감정/7.중립/0044_G2A5E7S0C0_KTH/0044_G2A5E7S0C0_KTH_000012.wav\"]  # 테스트 오디오 파일 경로 리스트\n",
    "test_labels = [\"기쁨\", \"슬픔\", \"분노\", \"불안\", \"상처\", \"당황\", \"중립\"]  # 테스트 라벨 리스트\n",
    "\n",
    "# HuBERT 특성 추출기와 LabelEncoder 로드\n",
    "feature_extractor = HuBERTFeatureExtractor()\n",
    "label_encoder_path = f\"./model/label_encoder.pkl\"\n",
    "dataset = EmotionDataset(test_audio_files, test_labels, feature_extractor, label_encoder_path)\n",
    "test_dataloader = DataLoader(dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# 모델 불러오기\n",
    "model_path = f\"./model/{folder_name}/model.pth\"\n",
    "device = torch.device(\"mps\")\n",
    "model = torch.load(model_path)\n",
    "model = model.to(device)\n",
    "\n",
    "# 테스트 실행\n",
    "predictions, ground_truth = test_model(test_dataloader, model, dataset)\n",
    "\n",
    "# 테스트 결과 출력\n",
    "predicted_labels = dataset.label_encoder.inverse_transform(predictions)\n",
    "ground_truth_labels = dataset.label_encoder.inverse_transform(ground_truth)\n",
    "\n",
    "# 정확도 계산\n",
    "correct_predictions = sum([1 for p, g in zip(predictions, ground_truth) if p == g])\n",
    "accuracy = correct_predictions / len(predictions)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Predictions: {predicted_labels}\")\n",
    "print(f\"Ground Truth: {ground_truth_labels}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoder loaded from ./model, label encoder/2025-01-13/label_encoder.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4h/8jkvbs3n7tlcqj21nw5kbbqm0000gn/T/ipykernel_35765/412774034.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(model_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: ['기쁨' '슬픔' '분노' '분노' '슬픔' '불안' '중립']\n"
     ]
    }
   ],
   "source": [
    "### 정확도 계산 X(예측만)\n",
    "\n",
    "# 테스트 데이터 준비\n",
    "test_audio_files = [\"./dataset/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/2.Validation/원천데이터/1.감정/1.기쁨/0029_G2A4E1S0C0_KJE/0029_G2A4E1S0C0_KJE_001970.wav\", \"./dataset/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/2.Validation/원천데이터/1.감정/2.슬픔/0033_G2A3E2S0C0_KMA/0033_G2A3E2S0C0_KMA_000020.wav\", \"./dataset/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/2.Validation/원천데이터/1.감정/3.분노/0018_G2A3E3S0C0_JBR/0018_G2A3E3S0C0_JBR_000019.wav\", \"./dataset/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/2.Validation/원천데이터/1.감정/4.불안/0012_G1A2E4S0C0_CHY/0012_G1A2E4S0C0_CHY_000011.wav\", \"./dataset/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/2.Validation/원천데이터/1.감정/5.상처/0005_G1A3E5S0C0_LJB/0005_G1A3E5S0C0_LJB_000014.wav\", \"./dataset/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/2.Validation/원천데이터/1.감정/6.당황/0020_G2A4E6S0C0_HGW/0020_G2A4E6S0C0_HGW_000009.wav\", \"./dataset/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/2.Validation/원천데이터/1.감정/7.중립/0044_G2A5E7S0C0_KTH/0044_G2A5E7S0C0_KTH_000012.wav\"]  # 테스트 오디오 파일 경로 리스트\n",
    "test_labels = [\"기쁨\", \"슬픔\", \"분노\", \"불안\", \"상처\", \"당황\", \"중립\"]  # 테스트 라벨 리스트\n",
    "\n",
    "# HuBERT 특성 추출기와 LabelEncoder 로드\n",
    "feature_extractor = HuBERTFeatureExtractor()\n",
    "label_encoder_path = f\"./model, label encoder/{folder_name}/label_encoder.pkl\"\n",
    "dataset = EmotionDataset(test_audio_files, test_labels, feature_extractor, label_encoder_path)\n",
    "test_dataloader = DataLoader(dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# 모델 불러오기\n",
    "model_path = f\"./model, label encoder/{folder_name}/model.pth\"\n",
    "device = torch.device(\"mps\")\n",
    "model = torch.load(model_path)\n",
    "model = model.to(device)\n",
    "\n",
    "# 정답 레이블 입력 X (예측만)\n",
    "# 테스트 실행\n",
    "predictions, _ = test_model(test_dataloader, model, dataset)\n",
    "\n",
    "# 예측값을 리버스 인코딩하여 감정 레이블로 변환\n",
    "predicted_labels = dataset.label_encoder.inverse_transform(predictions)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Predictions: {predicted_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_link = {'나쁜 녀석들: 라이드 오어 다이': 'https://youtu.be/_COstzwNXxc?si=YLovPvRmImAr1QIv', '수퍼 소닉 3': 'https://youtu.be/ngdTcr1FaDY?si=BY7uQyB6JllfCSu-'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\n",
      "'기쁨'에 맞는 추천 콘텐츠:\n",
      "\n",
      "1. 제목: 수퍼 소닉 3\n",
      "   개봉일: 2024-12-19\n",
      "   평점: 7.848\n",
      "   줄거리: 너클즈, 테일즈와 함께 평화로운 일상을 보내던 초특급 히어로 소닉. 연구 시설에 50년간 잠들어 있던 사상 최강의 비밀 병기 \"섀도우\"가 탈주하자, 세계 수호 통합 부대(약칭 세.수.통)에 의해 극비 소집된다. 소중한 것을 잃은 분노와 복수심에 불타는 섀도우는 소닉의 초고속 스피드와 너클즈의 최강 펀치를 단 단숨에 제압해버린다. 세상을 지배하려는 닥터 로보트닉과 그의 할아버지 제럴드 박사는 섀도우의 엄청난 힘 카오스 에너지를 이용해 인류를 정복하려고 하는데…\n",
      "   비디오 링크: https://youtu.be/ngdTcr1FaDY?si=BY7uQyB6JllfCSu-\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "'슬픔'에 맞는 추천 콘텐츠:\n",
      "\n",
      "1. 제목: Nr. 24\n",
      "   개봉일: 2024-10-30\n",
      "   평점: 7.239\n",
      "   줄거리: \n",
      "   비디오 링크: 없음\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "'분노'에 맞는 추천 콘텐츠:\n",
      "\n",
      "1. 제목: 헤러틱\n",
      "   개봉일: 2024-10-31\n",
      "   평점: 7.2\n",
      "   줄거리: 콜로라도의 작은 마을을 방문한 두 명의 젊은 몰몬교 여성 선교사들이 주민에게 복음을 전파하기 위해 집집마다 방문 중에 매력적인 리드 씨라는 인물을 만나게 되고, 그의 집에서 예상치 못한 위험에 휩싸이게 된다.\n",
      "   비디오 링크: 없음\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "'분노'에 맞는 추천 콘텐츠:\n",
      "\n",
      "1. 제목: 헤러틱\n",
      "   개봉일: 2024-10-31\n",
      "   평점: 7.2\n",
      "   줄거리: 콜로라도의 작은 마을을 방문한 두 명의 젊은 몰몬교 여성 선교사들이 주민에게 복음을 전파하기 위해 집집마다 방문 중에 매력적인 리드 씨라는 인물을 만나게 되고, 그의 집에서 예상치 못한 위험에 휩싸이게 된다.\n",
      "   비디오 링크: 없음\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "'슬픔'에 맞는 추천 콘텐츠:\n",
      "\n",
      "1. 제목: Nr. 24\n",
      "   개봉일: 2024-10-30\n",
      "   평점: 7.239\n",
      "   줄거리: \n",
      "   비디오 링크: 없음\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "'불안'에 맞는 추천 콘텐츠:\n",
      "\n",
      "1. 제목: 서브스턴스\n",
      "   개봉일: 2024-09-07\n",
      "   평점: 7.136\n",
      "   줄거리: 더 나은 버전의 당신을 꿈꿔본 적 있나요? 당신의 인생을 바꿔줄 신제품 ‘서브스턴스’. ‘서브스턴스’는 또 다른 당신을 만들어냅니다. 새롭고, 젊고, 더 아름답고, 더 완벽한 당신을. 단 한가지 규칙, 당신의 시간을 공유하면 됩니다. 당신을 위한 일주일, 새로운 당신을 위한 일주일, 각각 7일간의 완벽한 밸런스. 쉽죠? 균형을 존중한다면… 무엇이 잘못될 수 있을까요?\n",
      "   비디오 링크: 없음\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "'중립'에 맞는 추천 콘텐츠:\n",
      "\n",
      "1. 제목: 수퍼 소닉 3\n",
      "   개봉일: 2024-12-19\n",
      "   평점: 7.848\n",
      "   줄거리: 너클즈, 테일즈와 함께 평화로운 일상을 보내던 초특급 히어로 소닉. 연구 시설에 50년간 잠들어 있던 사상 최강의 비밀 병기 \"섀도우\"가 탈주하자, 세계 수호 통합 부대(약칭 세.수.통)에 의해 극비 소집된다. 소중한 것을 잃은 분노와 복수심에 불타는 섀도우는 소닉의 초고속 스피드와 너클즈의 최강 펀치를 단 단숨에 제압해버린다. 세상을 지배하려는 닥터 로보트닉과 그의 할아버지 제럴드 박사는 섀도우의 엄청난 힘 카오스 에너지를 이용해 인류를 정복하려고 하는데…\n",
      "   비디오 링크: https://youtu.be/ngdTcr1FaDY?si=BY7uQyB6JllfCSu-\n",
      "\n",
      "------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"------------------------------------\\n\")\n",
    "for i in predicted_labels:\n",
    "    recommendations = get_recommendations(i, 1)\n",
    "\n",
    "    if isinstance(recommendations, str):\n",
    "        print(recommendations)  # 에러 메시지 출력\n",
    "    else:\n",
    "        print(f\"'{i}'에 맞는 추천 콘텐츠:\")\n",
    "        for idx, movie in enumerate(recommendations, 1):\n",
    "            print(f\"\\n{idx}. 제목: {movie['title']}\")\n",
    "            print(f\"   개봉일: {movie['release_date']}\")\n",
    "            print(f\"   평점: {movie['vote_average']}\")\n",
    "            print(f\"   줄거리: {movie['overview']}\")\n",
    "            print(f\"   비디오 링크: {video_link.get(movie['title'], '없음')}\")\n",
    "        print(\"\\n------------------------------------\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voice-emotion-recognition_prototype",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
