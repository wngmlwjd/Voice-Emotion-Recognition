{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2FeatureExtractor, HubertModel\n",
    "import torchaudio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import pickle\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. HuBERT 특성 추출기 정의\n",
    "class HuBERTFeatureExtractor:\n",
    "    def __init__(self, model_name=\"facebook/hubert-base-ls960\"):\n",
    "        # HuBERT 모델과 프로세서 초기화\n",
    "        self.processor = Wav2Vec2FeatureExtractor.from_pretrained(model_name)\n",
    "        self.model = HubertModel.from_pretrained(model_name)\n",
    "        self.model.eval()  # 평가 모드로 설정\n",
    "\n",
    "    def load_audio(self, audio_file):\n",
    "        # 오디오 파일 로드\n",
    "        waveform, sample_rate = torchaudio.load(audio_file, format=\"wav\")\n",
    "        \n",
    "        return waveform, sample_rate\n",
    "\n",
    "    def preprocess_audio(self, waveform, sample_rate, target_sample_rate=16000, max_length=10):\n",
    "        # 모노로 변환\n",
    "        if waveform.size(0) > 1:\n",
    "            waveform = waveform.mean(dim=0, keepdim=True)\n",
    "        \n",
    "        # 샘플링 레이트 변환\n",
    "        if sample_rate != target_sample_rate:\n",
    "            resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=target_sample_rate)\n",
    "            waveform = resampler(waveform)\n",
    "            \n",
    "        max_samples = target_sample_rate * max_length\n",
    "        if waveform.size(1) > max_samples:\n",
    "            waveform = waveform[:, :max_samples]\n",
    "            \n",
    "        return waveform\n",
    "\n",
    "    def extract_features(self, audio_file):\n",
    "        # 오디오 로드 및 전처리\n",
    "        waveform, sample_rate = self.load_audio(audio_file)\n",
    "        waveform = self.preprocess_audio(waveform, sample_rate)\n",
    "        \n",
    "        # 입력 차원 확인 및 조정\n",
    "        if waveform.dim() == 1:\n",
    "            waveform = waveform.unsqueeze(0)\n",
    "        elif waveform.dim() == 2:\n",
    "            if waveform.size(0) > 1:\n",
    "                waveform = waveform.mean(dim=0, keepdim=True)\n",
    "        elif waveform.dim() == 3:\n",
    "            waveform = waveform.squeeze(0)\n",
    "            if waveform.size(0) > 1:\n",
    "                waveform = waveform.mean(dim=0, keepdim=True)\n",
    "        \n",
    "        # 특성 추출\n",
    "        inputs = self.processor(waveform, sampling_rate=16000, return_tensors=\"pt\", padding=True)\n",
    "        input_values = inputs.input_values\n",
    "        \n",
    "        # 불필요한 차원 제거\n",
    "        input_values = input_values.squeeze(1)  # (batch_size=1, sequence_length)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(input_values)\n",
    "            \n",
    "        features = outputs.last_hidden_state\n",
    "        \n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 데이터셋 클래스 정의\n",
    "class EmotionDataset:\n",
    "    def __init__(self, file_paths, feature_extractor):\n",
    "        self.file_paths = file_paths\n",
    "        self.feature_extractor = feature_extractor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        audio_path = self.file_paths[idx]\n",
    "        features = self.feature_extractor.extract_features(audio_path)\n",
    "        features = features.squeeze(0)  # (sequence_length, hidden_size)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Transformer 모델 정의\n",
    "class EmotionTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(EmotionTransformer, self).__init__()\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=input_dim, nhead=16),\n",
    "            num_layers=8\n",
    "        )\n",
    "        self.fc = nn.Linear(input_dim, num_classes)\n",
    "\n",
    "    def forward(self, x, src_key_padding_mask=None):\n",
    "        # Transformer를 통해 특성 추출\n",
    "        x = self.transformer(x, src_key_padding_mask=src_key_padding_mask)\n",
    "        x = x[-1]  # Sequence의 평균을 사용\n",
    "        output = self.fc(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_emotion(dataloader, model, label_encoder):\n",
    "    device = torch.device(\"mps\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for features in dataloader:\n",
    "            features = features.to(device)\n",
    "            outputs = model(features)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    # 예측값을 레이블로 변환\n",
    "    decoded_predictions = label_encoder.inverse_transform(predictions)\n",
    "    return decoded_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    features = [item for item in batch]\n",
    "    features = torch.nn.utils.rnn.pad_sequence(features, batch_first=True)  # [batch_size, sequence_length, feature_dim]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TMDB API 키\n",
    "TMDB_API_KEY = \"df9a0caaf2a07ee6babd7024a6accaf8\"\n",
    "    \n",
    "EMOTION_TO_GENRE = {\n",
    "    '기쁨': 35,  # Comedy\n",
    "    '슬픔': 18,  # Drama\n",
    "    '분노': 53,  # Thriller\n",
    "    '불안': 27,  # Horror\n",
    "    '상처': 80,  # Crime\n",
    "    '당황': 28,  # Action\n",
    "    '중립': 10751,  # Family\n",
    "}\n",
    "\n",
    "def get_recommendations(emotion, result_num=10, api_key=TMDB_API_KEY):\n",
    "    # 감정 매핑 확인\n",
    "    genre_id = EMOTION_TO_GENRE.get(emotion)\n",
    "    if not genre_id:\n",
    "        return f\"'{emotion}'에 해당하는 추천 장르가 없습니다. 감정을 다시 입력해주세요.\"\n",
    "\n",
    "    # TMDB Discover API 호출\n",
    "    url = f\"https://api.themoviedb.org/3/discover/movie\"\n",
    "    params = {\n",
    "        \"api_key\": api_key,\n",
    "        \"with_genres\": genre_id,\n",
    "        \"sort_by\": \"popularity.desc\",  # 인기 순으로 정렬\n",
    "        \"language\": \"ko-KR\",          # 한국어 결과\n",
    "        \"vote_average.gte\": 7.0,      # 평점 7 이상\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code != 200:\n",
    "        return f\"TMDB API 호출 실패: {response.status_code}\"\n",
    "\n",
    "    data = response.json()\n",
    "    results = data.get(\"results\", [])\n",
    "\n",
    "    if not results:\n",
    "        return f\"'{emotion}'에 맞는 추천 콘텐츠를 찾을 수 없습니다.\"\n",
    "\n",
    "    # 추천 콘텐츠 추출\n",
    "    recommendations = []\n",
    "    for movie in results[:result_num]:  # 상위 N개만 추출\n",
    "        recommendations.append({\n",
    "            \"title\": movie.get(\"title\"),\n",
    "            \"overview\": movie.get(\"overview\"),\n",
    "            \"vote_average\": movie.get(\"vote_average\"),\n",
    "            \"release_date\": movie.get(\"release_date\"),\n",
    "        })\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4h/8jkvbs3n7tlcqj21nw5kbbqm0000gn/T/ipykernel_45105/2282715700.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load('./model.pth')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EmotionTransformer(\n",
       "  (transformer): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-7): 8 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=768, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('./model.pth')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio File: 0014_G2A3E4S0C0_ASH_000002.wav -> Predicted Emotion: 불안\n"
     ]
    }
   ],
   "source": [
    "test_audio_file = [\"./dataset/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/2.Validation/원천데이터/1.감정/4.불안/0014_G2A3E4S0C0_ASH/0014_G2A3E4S0C0_ASH_000002.wav\"]  # 테스트할 오디오 파일 경로\n",
    "\n",
    "with open(\"./label_encoder.pkl\", \"rb\") as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "\n",
    "# Feature extractor 설정\n",
    "feature_extractor = HuBERTFeatureExtractor()\n",
    "\n",
    "# 테스트 데이터셋 및 DataLoader 생성\n",
    "test_dataset = EmotionDataset(test_audio_file, feature_extractor)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# 감정 예측\n",
    "predicted_emotions = predict_emotion(test_dataloader, model, label_encoder)\n",
    "\n",
    "# 결과 출력\n",
    "for audio_file, emotion in zip(test_audio_file, predicted_emotions):\n",
    "    print(f\"Audio File: {os.path.basename(audio_file)} -> Predicted Emotion: {emotion}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'불안'에 맞는 추천 콘텐츠:\n",
      "\n",
      "1. 제목: 서브스턴스\n",
      "   개봉일: 2024-09-07\n",
      "   평점: 7.149\n",
      "   줄거리: 더 나은 버전의 당신을 꿈꿔본 적 있나요? 당신의 인생을 바꿔줄 신제품 ‘서브스턴스’. ‘서브스턴스’는 또 다른 당신을 만들어냅니다. 새롭고, 젊고, 더 아름답고, 더 완벽한 당신을. 단 한가지 규칙, 당신의 시간을 공유하면 됩니다. 당신을 위한 일주일, 새로운 당신을 위한 일주일, 각각 7일간의 완벽한 밸런스. 쉽죠? 균형을 존중한다면… 무엇이 잘못될 수 있을까요?\n",
      "\n",
      "2. 제목: 헤러틱\n",
      "   개봉일: 2024-10-31\n",
      "   평점: 7.201\n",
      "   줄거리: 콜로라도의 작은 마을을 방문한 두 명의 젊은 몰몬교 여성 선교사들이 주민에게 복음을 전파하기 위해 집집마다 방문 중에 매력적인 리드 씨라는 인물을 만나게 되고, 그의 집에서 예상치 못한 위험에 휩싸이게 된다.\n",
      "\n",
      "3. 제목: 에이리언: 로물루스\n",
      "   개봉일: 2024-08-13\n",
      "   평점: 7.228\n",
      "   줄거리: 2142년, 부모 세대가 맞닥뜨렸던 암울한 미래를 피하려는 청년들이 더 나은 삶을 찾기 위해 식민지를 떠날 계획을 세운다. 하지만 버려진 우주 기지 로물루스에 도착한 이들은 악몽과도 같은 에이리언의 무자비한 공격에 쫓기기 시작한다. 그 누구도 그들의 절규를 들을 수 없는 우주 한가운데, 생존을 위한 치열한 사투를 벌여야 하는데...\n"
     ]
    }
   ],
   "source": [
    "recommendations = get_recommendations(emotion, 3)\n",
    "\n",
    "if isinstance(recommendations, str):\n",
    "    print(recommendations)  # 에러 메시지 출력\n",
    "else:\n",
    "    print(f\"'{emotion}'에 맞는 추천 콘텐츠:\")\n",
    "    for idx, movie in enumerate(recommendations, 1):\n",
    "        print(f\"\\n{idx}. 제목: {movie['title']}\")\n",
    "        print(f\"   개봉일: {movie['release_date']}\")\n",
    "        print(f\"   평점: {movie['vote_average']}\")\n",
    "        print(f\"   줄거리: {movie['overview']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voice-emotion-recognition_prototype",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
